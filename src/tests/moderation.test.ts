/**
 * ðŸ§ª Manual Test - OpenAI Moderation API
 * 
 * Script para probar manualmente todas las funcionalidades
 * de moderaciÃ³n implementadas.
 * 
 * Uso: npm run test:moderation
 */

import { ModerationService } from '../services/ModerationService';
import { 
  moderateUserComment, 
  batchContentFilter, 
  moderateEmailContent,
  smartAlertSystem,
  generateModerationStats,
  SAMPLE_DATA 
} from '../examples/moderation-examples';

async function runModerationTests() {
  console.log('ðŸ›¡ï¸  INICIANDO TESTS DE MODERACIÃ“N DE OPENAI API');
  console.log('=' .repeat(60));

  const moderationService = new ModerationService();

  try {
    // Test 1: ModeraciÃ³n bÃ¡sica
    console.log('\nðŸ“ TEST 1: ModeraciÃ³n de texto bÃ¡sico');
    console.log('-'.repeat(40));
    
    const safeText = "Hello! This is a friendly message.";
    const result1 = await moderationService.moderateText(safeText);
    console.log(`Texto: "${safeText}"`);
    console.log(`Resultado: ${result1.flagged ? 'FLAGGED' : 'SAFE'}`);
    console.log(`Score mÃ¡s alto: ${(result1.highest_scores[0]?.score * 100 || 0).toFixed(2)}%`);

    // Test 2: AnÃ¡lisis de riesgo
    console.log('\nðŸŽ¯ TEST 2: AnÃ¡lisis de riesgo');
    console.log('-'.repeat(40));
    
    const analysis = moderationService.analyzeModeration(result1);
    console.log(`Nivel de riesgo: ${analysis.risk_level}`);
    console.log(`RecomendaciÃ³n: ${analysis.recommendation}`);

    // Test 3: ModeraciÃ³n por lotes
    console.log('\nðŸ“¦ TEST 3: ModeraciÃ³n por lotes');
    console.log('-'.repeat(40));
    
    const testTexts = [
      ...SAMPLE_DATA.safeComments.slice(0, 3),
      ...SAMPLE_DATA.riskyComments.slice(0, 2)
    ];
    
    const batchResults = await moderationService.moderateTextBatch(testTexts);
    console.log(`Procesados: ${batchResults.length} textos`);
    console.log(`Flagged: ${batchResults.filter(r => r.flagged).length}`);
    console.log(`Safe: ${batchResults.filter(r => !r.flagged).length}`);

    // Test 4: ModeraciÃ³n de email
    console.log('\nðŸ“§ TEST 4: ModeraciÃ³n de email');
    console.log('-'.repeat(40));
    
    const email = SAMPLE_DATA.emails.marketing;
    const emailResult = await moderationService.moderateEmail(email.subject, email.body);
    console.log(`Subject flagged: ${emailResult.subject.flagged}`);
    console.log(`Body flagged: ${emailResult.body.flagged}`);
    console.log(`Overall safe: ${emailResult.overall_safe}`);

    // Test 5: Ejemplos prÃ¡cticos
    console.log('\nðŸ› ï¸  TEST 5: Ejemplos prÃ¡cticos');
    console.log('-'.repeat(40));
    
    // Comentario de usuario
    console.log('\nðŸ‘¤ Moderando comentario de usuario:');
    await moderateUserComment("This product is amazing! Love it!");

    // Filtrado por lotes
    console.log('\nðŸ”„ Filtrado por lotes:');
    const batchResult = await batchContentFilter(SAMPLE_DATA.safeComments.slice(0, 3));
    console.log(`Resultado: ${batchResult.approved} aprobados, ${batchResult.blocked} bloqueados`);

    // Email completo
    console.log('\nðŸ“® ModeraciÃ³n de email:');
    await moderateEmailContent(
      SAMPLE_DATA.emails.support.subject, 
      SAMPLE_DATA.emails.support.body
    );

    // Sistema de alertas
    console.log('\nðŸš¨ Sistema de alertas:');
    const alertResult = await smartAlertSystem("I love this product!");
    console.log(`Contenido seguro: ${alertResult.contentSafe}`);
    console.log(`Alertas generadas: ${alertResult.alerts.length}`);

    // EstadÃ­sticas
    console.log('\nðŸ“Š EstadÃ­sticas de moderaciÃ³n:');
    const stats = await generateModerationStats(SAMPLE_DATA.safeComments);
    console.log(`Stats generadas para ${stats.total} elementos`);

    console.log('\nâœ… TODOS LOS TESTS COMPLETADOS EXITOSAMENTE');
    console.log('=' .repeat(60));

  } catch (error) {
    console.error('âŒ ERROR EN TESTS:', error);
    console.log('=' .repeat(60));
  }
}

// FunciÃ³n para probar categorÃ­as
async function testCategories() {
  console.log('\nðŸ·ï¸  INFORMACIÃ“N DE CATEGORÃAS');
  console.log('-'.repeat(40));
  
  const categories = {
    harassment: 'Contenido de acoso hacia cualquier objetivo',
    'harassment/threatening': 'Acoso que incluye violencia o daÃ±o grave',
    hate: 'Contenido que promueve odio basado en raza, gÃ©nero, etc.',
    'hate/threatening': 'Contenido de odio que incluye violencia',
    'self-harm': 'Contenido que promueve actos de autolesiÃ³n',
    'self-harm/intent': 'ExpresiÃ³n de intenciÃ³n de autolesiÃ³n',
    'self-harm/instructions': 'Instrucciones para actos de autolesiÃ³n',
    sexual: 'Contenido destinado a excitaciÃ³n sexual',
    'sexual/minors': 'Contenido sexual que incluye menores de edad',
    violence: 'Contenido que representa muerte, violencia o lesiones',
    'violence/graphic': 'Violencia representada grÃ¡ficamente'
  };

  Object.entries(categories).forEach(([category, description]) => {
    console.log(`ðŸ“‹ ${category}: ${description}`);
  });
}

// Ejecutar si se llama directamente
if (require.main === module) {
  runModerationTests()
    .then(() => testCategories())
    .then(() => {
      console.log('\nðŸŽ“ Â¡Workshop de ModeraciÃ³n Completado!');
      console.log('Ahora estÃ¡s listo para implementar moderaciÃ³n de contenido en tus aplicaciones.');
      process.exit(0);
    })
    .catch(error => {
      console.error('Error en tests:', error);
      process.exit(1);
    });
}

export { runModerationTests, testCategories };
