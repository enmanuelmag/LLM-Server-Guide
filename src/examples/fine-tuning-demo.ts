import { FineTuningService } from '../services/FineTuningService.js';
import { EmailClassificationRequest } from '../types/fine-tuning.js';
import { Logger } from '../utils/logger.js';

/**
 * DemostraciÃ³n completa del uso del FineTuningService
 *
 * Este ejemplo muestra todas las funcionalidades necesarias para
 * la certificaciÃ³n OpenAI Practitioner en el mÃ³dulo de Fine-tuning:
 *
 * âœ… PreparaciÃ³n de datasets
 * âœ… CreaciÃ³n de jobs de fine-tuning
 * âœ… Monitoreo y mÃ©tricas
 * âœ… EvaluaciÃ³n de modelos
 * âœ… GestiÃ³n del ciclo de vida
 */
async function demonstrateFineTuning(): Promise<void> {
  Logger.info('ğŸ¯ DEMOSTRACIÃ“N COMPLETA DE FINE-TUNING CON OPENAI SDK');
  Logger.info('='.repeat(80));

  try {
    // Inicializar servicio
    const fineTuningService = new FineTuningService();

    // OPCIÃ“N 1: Ejecutar workflow completo automatizado
    Logger.info('\nğŸš€ OPCIÃ“N 1: Workflow Completo Automatizado');
    Logger.info('-'.repeat(50));

    // Descomenta la siguiente lÃ­nea para ejecutar todo el proceso
    // const modelId = await fineTuningService.executeCompleteWorkflow();
    // Logger.info(`âœ… Proceso completo finalizado. Modelo: ${modelId}`);

    // OPCIÃ“N 2: Paso a paso manual (para entendimiento detallado)
    Logger.info('\nğŸ”§ OPCIÃ“N 2: DemostraciÃ³n Paso a Paso');
    Logger.info('-'.repeat(50));

    // Paso 1: Preparar dataset
    Logger.info('\nğŸ“Š Preparando dataset...');
    const { trainingPath, validationPath } =
      await fineTuningService.prepareDataset();
    Logger.info(
      `âœ… Archivos creados:\n  - Training: ${trainingPath}\n  - Validation: ${validationPath}`
    );

    // Paso 2: Listar modelos existentes
    Logger.info('\nğŸ“‹ Listando modelos fine-tuned existentes...');
    await fineTuningService.listFineTunedModels();

    // Paso 3: Simular uso de un modelo (sin entrenar realmente)
    Logger.info('\nğŸ§ª Simulando clasificaciÃ³n de emails...');

    const testEmails: EmailClassificationRequest[] = [
      {
        emailSubject: 'Invoice #12345 - Payment Due',
        emailBody:
          'Your invoice for $1,500.00 is now due. Please process payment within 30 days. Reference: INV-2024-001',
        sender: 'billing@techcorp.com',
      },
      {
        emailSubject: 'Weekly Team Meeting',
        emailBody:
          'Reminder: Our weekly team sync is scheduled for tomorrow at 2 PM in Conference Room A. Please review the agenda attached.',
        sender: 'manager@company.com',
      },
      {
        emailSubject: 'Hotel Booking Confirmation',
        emailBody:
          'Your reservation at Downtown Marriott is confirmed. Total: $450.00 for 2 nights. Check-in: March 15th.',
        sender: 'noreply@marriott.com',
      },
      {
        emailSubject: 'Marketing Newsletter - March 2024',
        emailBody:
          'Check out our latest product updates, industry insights, and upcoming webinars. Subscribe for weekly updates!',
        sender: 'newsletter@startup.com',
      },
    ];

    // Simular clasificaciÃ³n con modelo base (disponible inmediatamente)
    Logger.info('\nğŸ¤– Clasificando emails con modelo base (gpt-3.5-turbo)...');
    for (let i = 0; i < testEmails.length; i++) {
      const email = testEmails[i];
      Logger.info(`\nğŸ“§ Email ${i + 1}: "${email.emailSubject}"`);

      try {
        // Nota: En una implementaciÃ³n real, usarÃ­as el modelo fine-tuned aquÃ­
        // const result = await fineTuningService.classifyEmailWithFineTunedModel(modelId, email);

        // Por ahora, mostramos cÃ³mo se verÃ­a la estructura de respuesta
        const mockResult = {
          isFinancial:
            email.emailSubject.toLowerCase().includes('invoice') ||
            email.emailSubject.toLowerCase().includes('payment') ||
            email.emailBody.includes('$'),
          confidence: Math.random() * 0.3 + 0.7, // 0.7-1.0
          category: email.emailBody.includes('$')
            ? 'financial-transaction'
            : 'non-financial',
          reasoning: `Email analizado por contenido financiero: ${email.emailBody.substring(
            0,
            50
          )}...`,
          extractedAmount: email.emailBody.match(/\$[\d,]+\.?\d*/)?.[0]
            ? {
                value: parseFloat(
                  email.emailBody
                    .match(/\$[\d,]+\.?\d*/)![0]
                    .replace('$', '')
                    .replace(',', '')
                ),
                currency: 'USD',
              }
            : undefined,
        };

        Logger.info(
          `  ğŸ“Š Resultado: ${
            mockResult.isFinancial ? 'ğŸ’° Financiero' : 'ğŸ“ No financiero'
          }`
        );
        Logger.info(`  ğŸ¯ CategorÃ­a: ${mockResult.category}`);
        Logger.info(
          `  ğŸ“ˆ Confianza: ${(mockResult.confidence * 100).toFixed(1)}%`
        );
        if (mockResult.extractedAmount) {
          Logger.info(
            `  ğŸ’µ Monto: ${mockResult.extractedAmount.currency} ${mockResult.extractedAmount.value}`
          );
        }
        Logger.info(`  ğŸ’­ RazÃ³n: ${mockResult.reasoning}`);
      } catch (error) {
        Logger.error(`âŒ Error clasificando email ${i + 1}:`, error);
      }
    }

    // INFORMACIÃ“N EDUCATIVA SOBRE EL PROCESO
    Logger.info('\nğŸ“š INFORMACIÃ“N EDUCATIVA - PROCESO COMPLETO DE FINE-TUNING');
    Logger.info('='.repeat(80));

    Logger.info(`
ğŸ”§ PREPARACIÃ“N DEL DATASET:
   â€¢ Formato JSONL con estructura de mensajes (system, user, assistant)
   â€¢ DivisiÃ³n en entrenamiento (80%) y validaciÃ³n (20%)
   â€¢ ValidaciÃ³n de estructura y longitud de contenido
   â€¢ MÃ­nimo recomendado: 50-100 ejemplos de calidad

ğŸ’¾ SUBIDA DE ARCHIVOS:
   â€¢ Archivos convertidos a formato compatible con OpenAI
   â€¢ Uso de File API para subida correcta
   â€¢ Archivos de validaciÃ³n opcionales pero recomendados

âš™ï¸ CONFIGURACIÃ“N DEL JOB:
   â€¢ Modelo base: gpt-3.5-turbo-1106 (recomendado)
   â€¢ HiperparÃ¡metros:
     - n_epochs: 3 (1-50, auto por defecto)
     - batch_size: 1 (auto o potencias de 2)
     - learning_rate_multiplier: 0.1 (0.02-2.0)
   â€¢ Sufijo personalizado para identificaciÃ³n

ğŸ“Š MONITOREO Y MÃ‰TRICAS:
   â€¢ Polling del estado del job cada 30 segundos
   â€¢ Eventos de progreso en tiempo real
   â€¢ Descarga de archivos de resultados con mÃ©tricas
   â€¢ Training/validation loss tracking

ğŸ§ª EVALUACIÃ“N:
   â€¢ ComparaciÃ³n con modelo base
   â€¢ MÃ©tricas de precisiÃ³n y recall
   â€¢ AnÃ¡lisis de mejora porcentual
   â€¢ Casos de prueba especÃ­ficos del dominio

ğŸ”„ GESTIÃ“N DEL CICLO DE VIDA:
   â€¢ Listado de modelos fine-tuned
   â€¢ InformaciÃ³n de creaciÃ³n y propietario
   â€¢ EliminaciÃ³n de modelos obsoletos
   â€¢ Control de costos y recursos
    `);

    Logger.info('\nğŸ’¡ PRÃ“XIMOS PASOS PARA FINE-TUNING REAL:');
    Logger.info(`
1. Configurar variable de entorno OPENAI_API_KEY
2. Descomentar la lÃ­nea del workflow completo
3. Ejecutar: npm run dev
4. Esperar completar el entrenamiento (~10-30 minutos)
5. Usar el modelo resultante para predicciones en producciÃ³n

ğŸ’° CONSIDERACIONES DE COSTO:
â€¢ Fine-tuning: ~$0.008 por 1K tokens de entrenamiento
â€¢ Uso del modelo: ~$0.012 por 1K tokens (vs $0.002 del base)
â€¢ Archivos de entrenamiento se almacenan por 30 dÃ­as
    `);

    Logger.info('\nâœ… DEMOSTRACIÃ“N COMPLETA FINALIZADA');
    Logger.info('='.repeat(80));
  } catch (error) {
    Logger.error('âŒ Error en la demostraciÃ³n:', error);

    if (error instanceof Error) {
      if (error.message.includes('OPENAI_API_KEY')) {
        Logger.info('\nğŸ’¡ SOLUCIÃ“N: Configura tu API key de OpenAI:');
        Logger.info('   1. Crea un archivo .env en la raÃ­z del proyecto');
        Logger.info('   2. Agrega: OPENAI_API_KEY=tu_api_key_aqui');
        Logger.info(
          '   3. ObtÃ©n tu API key en: https://platform.openai.com/api-keys'
        );
      }
    }
  }
}

/**
 * FunciÃ³n auxiliar para mostrar informaciÃ³n sobre fine-tuning
 */
async function showFineTuningInfo(): Promise<void> {
  Logger.info('ğŸ“‹ INFORMACIÃ“N SOBRE FINE-TUNING PARA CERTIFICACIÃ“N OPENAI');
  Logger.info('='.repeat(80));

  const topics = [
    {
      title: 'ğŸ¯ Â¿CuÃ¡ndo usar Fine-tuning?',
      content: `
â€¢ Mejorar rendimiento en tareas especÃ­ficas del dominio
â€¢ Cuando pocos ejemplos en el prompt no son suficientes
â€¢ Para generar respuestas mÃ¡s consistentes y estructuradas
â€¢ Reducir latencia eliminando ejemplos largos del prompt
â€¢ Personalizar el comportamiento del modelo para casos de uso especÃ­ficos`,
    },
    {
      title: 'ğŸ“Š PreparaciÃ³n de Datos',
      content: `
â€¢ Formato JSONL con conversaciones de ejemplo
â€¢ MÃ­nimo 10 ejemplos, recomendado 50-100 de alta calidad
â€¢ Estructura: {"messages": [{"role": "system/user/assistant", "content": "..."}]}
â€¢ Longitud mÃ¡xima: 4,096 tokens por ejemplo
â€¢ DivisiÃ³n train/validation recomendada: 80/20`,
    },
    {
      title: 'âš™ï¸ ConfiguraciÃ³n de HiperparÃ¡metros',
      content: `
â€¢ n_epochs: NÃºmero de pasadas por el dataset (1-50, auto por defecto)
â€¢ batch_size: TamaÃ±o del lote (auto, 1, 2, 4, 8, 16)
â€¢ learning_rate_multiplier: Control de velocidad de aprendizaje (0.02-2.0)
â€¢ Validation split automÃ¡tico si no se proporciona archivo de validaciÃ³n`,
    },
    {
      title: 'ğŸ“ˆ MÃ©tricas y EvaluaciÃ³n',
      content: `
â€¢ Training loss: DisminuciÃ³n indica aprendizaje
â€¢ Validation loss: Previene overfitting
â€¢ Accuracy: ComparaciÃ³n con modelo base
â€¢ Custom metrics: EspecÃ­ficas del dominio (precision, recall, F1)
â€¢ A/B testing: Comparar modelos en producciÃ³n`,
    },
    {
      title: 'ğŸ’° Costos y Consideraciones',
      content: `
â€¢ Training: ~$0.008/1K tokens
â€¢ Usage: Precio superior al modelo base (~6x para GPT-3.5)
â€¢ Storage: Archivos se mantienen 30 dÃ­as gratuito
â€¢ Tiempo: 10-30 minutos tÃ­pico para datasets pequeÃ±os
â€¢ LÃ­mites: 3 jobs simultÃ¡neos, 50 modelos personalizados`,
    },
  ];

  for (const topic of topics) {
    Logger.info(`\n${topic.title}`);
    Logger.info('-'.repeat(50));
    Logger.info(topic.content);
  }

  Logger.info('\nğŸ”— RECURSOS ADICIONALES:');
  Logger.info(`
ğŸ“– DocumentaciÃ³n oficial: https://platform.openai.com/docs/guides/fine-tuning
ğŸ› ï¸ Best practices: https://cookbook.openai.com/examples/fine-tuning_classification
ğŸ“Š Pricing: https://openai.com/pricing
ğŸ“ Fine-tuning guide: https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset
  `);
}

// FunciÃ³n principal
async function main(): Promise<void> {
  try {
    // Mostrar informaciÃ³n educativa primero
    await showFineTuningInfo();

    // Luego la demostraciÃ³n prÃ¡ctica
    await demonstrateFineTuning();
  } catch (error) {
    Logger.error('âŒ Error en la aplicaciÃ³n:', error);
    process.exit(1);
  }
}

// Ejecutar solo si es el archivo principal
// En un entorno real, puedes ejecutar: node dist/examples/fine-tuning-demo.js
// main();

export { demonstrateFineTuning, showFineTuningInfo };
