import { FineTuningService } from '../services/FineTuningService.js';
import { EmailClassificationRequest } from '../types/fine-tuning.js';
import { Logger } from '../utils/logger.js';

/**
 * Demostraci√≥n completa del uso del FineTuningService
 *
 * Este ejemplo muestra todas las funcionalidades necesarias para
 * la certificaci√≥n OpenAI Practitioner en el m√≥dulo de Fine-tuning:
 *
 * ‚úÖ Preparaci√≥n de datasets
 * ‚úÖ Creaci√≥n de jobs de fine-tuning
 * ‚úÖ Monitoreo y m√©tricas
 * ‚úÖ Evaluaci√≥n de modelos
 * ‚úÖ Gesti√≥n del ciclo de vida
 */
async function demonstrateFineTuning(): Promise<void> {
  Logger.info('üéØ DEMOSTRACI√ìN COMPLETA DE FINE-TUNING CON OPENAI SDK');
  Logger.info('='.repeat(80));

  try {
    // Inicializar servicio
    const fineTuningService = new FineTuningService();

    // OPCI√ìN 1: Ejecutar workflow completo automatizado
    Logger.info('\nüöÄ OPCI√ìN 1: Workflow Completo Automatizado');
    Logger.info('-'.repeat(50));

    // Descomenta la siguiente l√≠nea para ejecutar todo el proceso
    // const modelId = await fineTuningService.executeCompleteWorkflow();
    // Logger.info(`‚úÖ Proceso completo finalizado. Modelo: ${modelId}`);

    // OPCI√ìN 2: Paso a paso manual (para entendimiento detallado)
    Logger.info('\nüîß OPCI√ìN 2: Demostraci√≥n Paso a Paso');
    Logger.info('-'.repeat(50));

    // Paso 1: Preparar dataset
    Logger.info('\nüìä Preparando dataset...');
    const { trainingPath, validationPath } =
      await fineTuningService.prepareDataset();
    Logger.info(
      `‚úÖ Archivos creados:\n  - Training: ${trainingPath}\n  - Validation: ${validationPath}`
    );

    // Paso 2: Listar modelos existentes
    Logger.info('\nüìã Listando modelos fine-tuned existentes...');
    await fineTuningService.listFineTunedModels();

    // Paso 3: Simular uso de un modelo (sin entrenar realmente)
    Logger.info('\nüß™ Simulando clasificaci√≥n de emails...');

    const testEmails: EmailClassificationRequest[] = [
      {
        emailSubject: 'Invoice #12345 - Payment Due',
        emailBody:
          'Your invoice for $1,500.00 is now due. Please process payment within 30 days. Reference: INV-2024-001',
        sender: 'billing@techcorp.com',
      },
      {
        emailSubject: 'Weekly Team Meeting',
        emailBody:
          'Reminder: Our weekly team sync is scheduled for tomorrow at 2 PM in Conference Room A. Please review the agenda attached.',
        sender: 'manager@company.com',
      },
      {
        emailSubject: 'Hotel Booking Confirmation',
        emailBody:
          'Your reservation at Downtown Marriott is confirmed. Total: $450.00 for 2 nights. Check-in: March 15th.',
        sender: 'noreply@marriott.com',
      },
      {
        emailSubject: 'Marketing Newsletter - March 2024',
        emailBody:
          'Check out our latest product updates, industry insights, and upcoming webinars. Subscribe for weekly updates!',
        sender: 'newsletter@startup.com',
      },
    ];

    // Simular clasificaci√≥n con modelo base (disponible inmediatamente)
    Logger.info('\nü§ñ Clasificando emails con modelo base (gpt-3.5-turbo)...');
    for (let i = 0; i < testEmails.length; i++) {
      const email = testEmails[i];
      Logger.info(`\nüìß Email ${i + 1}: "${email.emailSubject}"`);

      try {
        // Nota: En una implementaci√≥n real, usar√≠as el modelo fine-tuned aqu√≠
        // const result = await fineTuningService.classifyEmailWithFineTunedModel(modelId, email);

        // Por ahora, mostramos c√≥mo se ver√≠a la estructura de respuesta
        const mockResult = {
          isFinancial:
            email.emailSubject.toLowerCase().includes('invoice') ||
            email.emailSubject.toLowerCase().includes('payment') ||
            email.emailBody.includes('$'),
          confidence: Math.random() * 0.3 + 0.7, // 0.7-1.0
          category: email.emailBody.includes('$')
            ? 'financial-transaction'
            : 'non-financial',
          reasoning: `Email analizado por contenido financiero: ${email.emailBody.substring(
            0,
            50
          )}...`,
          extractedAmount: email.emailBody.match(/\$[\d,]+\.?\d*/)?.[0]
            ? {
                value: parseFloat(
                  email.emailBody
                    .match(/\$[\d,]+\.?\d*/)![0]
                    .replace('$', '')
                    .replace(',', '')
                ),
                currency: 'USD',
              }
            : undefined,
        };

        Logger.info(
          `  üìä Resultado: ${
            mockResult.isFinancial ? 'üí∞ Financiero' : 'üìù No financiero'
          }`
        );
        Logger.info(`  üéØ Categor√≠a: ${mockResult.category}`);
        Logger.info(
          `  üìà Confianza: ${(mockResult.confidence * 100).toFixed(1)}%`
        );
        if (mockResult.extractedAmount) {
          Logger.info(
            `  üíµ Monto: ${mockResult.extractedAmount.currency} ${mockResult.extractedAmount.value}`
          );
        }
        Logger.info(`  üí≠ Raz√≥n: ${mockResult.reasoning}`);
      } catch (error) {
        Logger.error(`‚ùå Error clasificando email ${i + 1}:`, error);
      }
    }

    // INFORMACI√ìN EDUCATIVA SOBRE EL PROCESO
    Logger.info('\nüìö INFORMACI√ìN EDUCATIVA - PROCESO COMPLETO DE FINE-TUNING');
    Logger.info('='.repeat(80));

    Logger.info(`
üîß PREPARACI√ìN DEL DATASET:
   ‚Ä¢ Formato JSONL con estructura de mensajes (system, user, assistant)
   ‚Ä¢ Divisi√≥n en entrenamiento (80%) y validaci√≥n (20%)
   ‚Ä¢ Validaci√≥n de estructura y longitud de contenido
   ‚Ä¢ M√≠nimo recomendado: 50-100 ejemplos de calidad

üíæ SUBIDA DE ARCHIVOS:
   ‚Ä¢ Archivos convertidos a formato compatible con OpenAI
   ‚Ä¢ Uso de File API para subida correcta
   ‚Ä¢ Archivos de validaci√≥n opcionales pero recomendados

‚öôÔ∏è CONFIGURACI√ìN DEL JOB:
   ‚Ä¢ Modelo base: gpt-3.5-turbo-1106 (recomendado)
   ‚Ä¢ Hiperpar√°metros:
     - n_epochs: 3 (1-50, auto por defecto)
     - batch_size: 1 (auto o potencias de 2)
     - learning_rate_multiplier: 0.1 (0.02-2.0)
   ‚Ä¢ Sufijo personalizado para identificaci√≥n

üìä MONITOREO Y M√âTRICAS:
   ‚Ä¢ Polling del estado del job cada 30 segundos
   ‚Ä¢ Eventos de progreso en tiempo real
   ‚Ä¢ Descarga de archivos de resultados con m√©tricas
   ‚Ä¢ Training/validation loss tracking

üß™ EVALUACI√ìN:
   ‚Ä¢ Comparaci√≥n con modelo base
   ‚Ä¢ M√©tricas de precisi√≥n y recall
   ‚Ä¢ An√°lisis de mejora porcentual
   ‚Ä¢ Casos de prueba espec√≠ficos del dominio

üîÑ GESTI√ìN DEL CICLO DE VIDA:
   ‚Ä¢ Listado de modelos fine-tuned
   ‚Ä¢ Informaci√≥n de creaci√≥n y propietario
   ‚Ä¢ Eliminaci√≥n de modelos obsoletos
   ‚Ä¢ Control de costos y recursos
    `);

    Logger.info('\nüí° PR√ìXIMOS PASOS PARA FINE-TUNING REAL:');
    Logger.info(`
1. Configurar variable de entorno OPENAI_API_KEY
2. Descomentar la l√≠nea del workflow completo
3. Ejecutar: npm run dev
4. Esperar completar el entrenamiento (~10-30 minutos)
5. Usar el modelo resultante para predicciones en producci√≥n

üí∞ CONSIDERACIONES DE COSTO:
‚Ä¢ Fine-tuning: ~$0.008 por 1K tokens de entrenamiento
‚Ä¢ Uso del modelo: ~$0.012 por 1K tokens (vs $0.002 del base)
‚Ä¢ Archivos de entrenamiento se almacenan por 30 d√≠as
    `);

    Logger.info('\n‚úÖ DEMOSTRACI√ìN COMPLETA FINALIZADA');
    Logger.info('='.repeat(80));
  } catch (error) {
    Logger.error('‚ùå Error en la demostraci√≥n:', error);

    if (error instanceof Error) {
      if (error.message.includes('OPENAI_API_KEY')) {
        Logger.info('\nüí° SOLUCI√ìN: Configura tu API key de OpenAI:');
        Logger.info('   1. Crea un archivo .env en la ra√≠z del proyecto');
        Logger.info('   2. Agrega: OPENAI_API_KEY=tu_api_key_aqui');
        Logger.info(
          '   3. Obt√©n tu API key en: https://platform.openai.com/api-keys'
        );
      }
    }
  }
}

/**
 * Funci√≥n auxiliar para mostrar informaci√≥n sobre fine-tuning
 */
async function showFineTuningInfo(): Promise<void> {
  Logger.info('üìã INFORMACI√ìN SOBRE FINE-TUNING PARA CERTIFICACI√ìN OPENAI');
  Logger.info('='.repeat(80));

  const topics = [
    {
      title: 'üéØ ¬øCu√°ndo usar Fine-tuning?',
      content: `
‚Ä¢ Mejorar rendimiento en tareas espec√≠ficas del dominio
‚Ä¢ Cuando pocos ejemplos en el prompt no son suficientes
‚Ä¢ Para generar respuestas m√°s consistentes y estructuradas
‚Ä¢ Reducir latencia eliminando ejemplos largos del prompt
‚Ä¢ Personalizar el comportamiento del modelo para casos de uso espec√≠ficos`,
    },
    {
      title: 'üìä Preparaci√≥n de Datos',
      content: `
‚Ä¢ Formato JSONL con conversaciones de ejemplo
‚Ä¢ M√≠nimo 10 ejemplos, recomendado 50-100 de alta calidad
‚Ä¢ Estructura: {"messages": [{"role": "system/user/assistant", "content": "..."}]}
‚Ä¢ Longitud m√°xima: 4,096 tokens por ejemplo
‚Ä¢ Divisi√≥n train/validation recomendada: 80/20`,
    },
    {
      title: '‚öôÔ∏è Configuraci√≥n de Hiperpar√°metros',
      content: `
‚Ä¢ n_epochs: N√∫mero de pasadas por el dataset (1-50, auto por defecto)
‚Ä¢ batch_size: Tama√±o del lote (auto, 1, 2, 4, 8, 16)
‚Ä¢ learning_rate_multiplier: Control de velocidad de aprendizaje (0.02-2.0)
‚Ä¢ Validation split autom√°tico si no se proporciona archivo de validaci√≥n`,
    },
    {
      title: 'üìà M√©tricas y Evaluaci√≥n',
      content: `
‚Ä¢ Training loss: Disminuci√≥n indica aprendizaje
‚Ä¢ Validation loss: Previene overfitting
‚Ä¢ Accuracy: Comparaci√≥n con modelo base
‚Ä¢ Custom metrics: Espec√≠ficas del dominio (precision, recall, F1)
‚Ä¢ A/B testing: Comparar modelos en producci√≥n`,
    },
    {
      title: 'üí∞ Costos y Consideraciones',
      content: `
‚Ä¢ Training: ~$0.008/1K tokens
‚Ä¢ Usage: Precio superior al modelo base (~6x para GPT-3.5)
‚Ä¢ Storage: Archivos se mantienen 30 d√≠as gratuito
‚Ä¢ Tiempo: 10-30 minutos t√≠pico para datasets peque√±os
‚Ä¢ L√≠mites: 3 jobs simult√°neos, 50 modelos personalizados`,
    },
  ];

  for (const topic of topics) {
    Logger.info(`\n${topic.title}`);
    Logger.info('-'.repeat(50));
    Logger.info(topic.content);
  }

  Logger.info('\nüîó RECURSOS ADICIONALES:');
  Logger.info(`
üìñ Documentaci√≥n oficial: https://platform.openai.com/docs/guides/fine-tuning
üõ†Ô∏è Best practices: https://cookbook.openai.com/examples/fine-tuning_classification
üìä Pricing: https://openai.com/pricing
üéì Fine-tuning guide: https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset
  `);
}

// Funci√≥n principal
async function main(): Promise<void> {
  try {
    // Mostrar informaci√≥n educativa primero
    await showFineTuningInfo();

    // Luego la demostraci√≥n pr√°ctica
    await demonstrateFineTuning();
  } catch (error) {
    Logger.error('‚ùå Error en la aplicaci√≥n:', error);
    process.exit(1);
  }
}

// Ejecutar solo si es el archivo principal
// En un entorno real, puedes ejecutar: node dist/examples/fine-tuning-demo.js
// main();

export { demonstrateFineTuning, showFineTuningInfo };
