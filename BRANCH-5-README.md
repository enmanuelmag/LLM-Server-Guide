# Rama 5: OpenAI Moderation API

## üõ°Ô∏è Descripci√≥n

Esta rama implementa el **OpenAI Moderation API** para an√°lisis de contenido y seguridad. Aprender√°s a usar la API de moderaci√≥n para detectar y analizar contenido potencialmente da√±ino en textos y emails.

## ‚ú® Caracter√≠sticas Implementadas

### üîß ModerationService
- **Moderaci√≥n de texto individual**: Analiza un texto √∫nico
- **Moderaci√≥n en lotes**: Procesa m√∫ltiples textos simult√°neamente  
- **Moderaci√≥n de emails**: Analiza asunto y cuerpo por separado
- **An√°lisis de riesgo**: Proporciona recomendaciones basadas en los resultados

### üåê API Endpoints

#### POST `/api/moderation/text`
Modera un texto individual
```json
{
  "text": "Tu texto aqu√≠"
}
```

#### POST `/api/moderation/batch`
Modera m√∫ltiples textos (m√°ximo 10)
```json
{
  "texts": ["Texto 1", "Texto 2", "Texto 3"]
}
```

#### POST `/api/moderation/email`
Modera contenido de email completo
```json
{
  "subject": "Asunto del email",
  "body": "Contenido del email"
}
```

#### GET `/api/moderation/categories`
Obtiene informaci√≥n sobre las categor√≠as de moderaci√≥n

#### POST `/api/moderation/demo`
Endpoint de demostraci√≥n con textos de ejemplo

## üöÄ C√≥mo Usar

### 1. Configurar Variables de Entorno
```bash
# Copia el archivo de ejemplo
cp .env.example .env

# Edita y agrega tu API key de OpenAI
OPENAI_API_KEY=tu_api_key_aqui
```

### 2. Instalar Dependencias
```bash
npm install
```

### 3. Compilar y Ejecutar
```bash
# Compilar
npm run build

# Ejecutar
npm start

# O en modo desarrollo
npm run dev
```

### 4. Probar la API

#### Prueba B√°sica
```bash
curl -X POST http://localhost:3000/api/moderation/text \
  -H "Content-Type: application/json" \
  -d '{"text": "Hello, this is a safe message!"}'
```

#### Demo Interactiva
```bash
curl -X POST http://localhost:3000/api/moderation/demo \
  -H "Content-Type: application/json" \
  -d '{"include_risky": false}'
```

## üìä Categor√≠as de Moderaci√≥n

El API analiza estas categor√≠as:

- **harassment**: Contenido de acoso
- **harassment/threatening**: Acoso con amenazas
- **hate**: Contenido de odio  
- **hate/threatening**: Odio con amenazas
- **self-harm**: Contenido de autolesiones
- **self-harm/intent**: Intenci√≥n de autolesi√≥n
- **self-harm/instructions**: Instrucciones de autolesi√≥n
- **sexual**: Contenido sexual
- **sexual/minors**: Contenido sexual con menores
- **violence**: Contenido violento
- **violence/graphic**: Violencia gr√°fica

## üéØ Casos de Uso

### 1. **Moderaci√≥n de Comentarios**
```javascript
const result = await moderationService.moderateText(userComment);
if (result.flagged) {
  // Bloquear o revisar comentario
}
```

### 2. **Filtro de Emails**
```javascript
const emailResult = await moderationService.moderateEmail(subject, body);
if (!emailResult.overall_safe) {
  // Requerir revisi√≥n manual
}
```

### 3. **An√°lisis de Contenido por Lotes**
```javascript
const results = await moderationService.moderateTextBatch(textArray);
const flaggedContent = results.filter(r => r.flagged);
```

## üîç Respuesta Detallada

La API devuelve informaci√≥n completa:

```json
{
  "success": true,
  "data": {
    "moderation": {
      "flagged": false,
      "categories": { ... },
      "category_scores": { ... },
      "flagged_categories": [],
      "highest_scores": [
        { "category": "harassment", "score": 0.001 }
      ]
    },
    "analysis": {
      "risk_level": "low",
      "primary_concerns": [],
      "recommendation": "Content appears safe for general use.",
      "score_analysis": "Highest risk score: 0.1% in harassment"
    }
  }
}
```

## üîß Configuraci√≥n Avanzada

### Umbrales Personalizados
Puedes ajustar los umbrales de riesgo en `ModerationService.analyzeModeration()`:

- **Alto riesgo**: Puntuaci√≥n > 0.8 o m√∫ltiples categor√≠as
- **Riesgo medio**: Puntuaci√≥n > 0.5
- **Bajo riesgo**: Puntuaci√≥n < 0.3

### Integraci√≥n con Sistemas de Filtrado
```javascript
// Ejemplo de integraci√≥n
const moderationResult = await moderationService.moderateText(content);
const analysis = moderationService.analyzeModeration(moderationResult);

switch (analysis.risk_level) {
  case 'high':
    // Bloquear autom√°ticamente
    break;
  case 'medium':
    // Enviar a cola de revisi√≥n
    break;
  case 'low':
    // Permitir publicaci√≥n
    break;
}
```

## üìö Recursos Adicionales

- [OpenAI Moderation API Docs](https://platform.openai.com/docs/guides/moderation)
- [Content Policy Guidelines](https://openai.com/usage-policies)
- [Best Practices for Content Moderation](https://platform.openai.com/docs/guides/moderation/best-practices)

## üéì Logros del Workshop

¬°Felicidades! Has completado todas las ramas del workshop:

1. ‚úÖ **Rama 1**: Configuraci√≥n inicial y OpenAI SDK
2. ‚úÖ **Rama 2**: RAG con embeddings y pol√≠ticas financieras
3. ‚úÖ **Rama 3**: Fine-tuning para clasificaci√≥n de emails
4. ‚úÖ **Rama 4**: Procesador completo de emails con simulaci√≥n
5. ‚úÖ **Rama 5**: API de moderaci√≥n y seguridad de contenido

Ahora tienes conocimiento completo del ecosistema OpenAI API y est√°s listo para la certificaci√≥n **OpenAI API Practitioner**! üöÄ
